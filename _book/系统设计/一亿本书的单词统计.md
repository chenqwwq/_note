# 一亿本书的单词统计

> 基本条件如下

1. 内存不设限
2. 单词用英文单词隔开
3. 提供书名（和书本内容组成类似 K，V 的样式



## 基本思路

使用 Map 遍历一亿本书，使用单词做为 Key，个数作为 Value。（或者不考虑任何优化，可以使用字典树去统计整体的单词。

> 考虑使用多线程

多线程分别读取一亿本书，就需要对书进行划分。

划分的方案有很多，可以使用26个线程并且以书本的首字母做为分片依据，或者使用 n 个线程，对书本名的 Hash mod n 作为分片依据。

> 优化书本的分派

如果直接使用 n 个线程读取，那对书本名的判断需要事先计算，不是再换下一个。

这里可以做到优化是在起一个分派线程，起用 n 个队列，分别保存 n 个 IO 读取线程需要处理的书名，单分派线程读取书名并做分派，IO 线程只需要处理自己队列的书本。

> 考虑 IO 线程异常

以书本为单位，统计每个书本的 Map，成功可以标记该书本已经成功，中途出现异常之后需要重新读取一个书本的所有单词。





## 最终方案

使用最少两种线程：

1. 分派线程（用于分派所有的书本到队列
2. IO 线程（负责读取书本中的所有单词，每个 IO 线程绑定一个队列，从队列中读取，完毕之后弹出

结果以书本和 Map 的 <K，V> 形式保存，IO 线程如果中途出现异常，在书本没统计完成的时候可以重新统计该本书（只要队列没有弹出。

